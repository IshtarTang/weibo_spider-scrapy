日志2为新版微博记录

2022.10.16
在写爬新版微博页面的程序，还不能用，明天尽量把评论和失败重试给写了

2022.10.18
新版程序能跑了，不过目前的状态算是强行拼凑起来的，除了我之外任何人动都会炸
要给它写个判断重复次数的中间件才行

2022.11.14
旧版页面要被停用了，旧版的爬虫会停止更新，新版的慢慢写

2022.11.30
调整了下结构
想用custom_settings设日志但是没效果，可能只能配自己的组件？等把新版pipline写出来再试试
写了新的微相册下图片程序。不知道微相册以后会不会停用，要是停用就只能再写新的了，还没搞明白新版微博的大图加载机制

2022.12.16（旧版共用）
修改了pipline结构：聚合部分代码单独拿出来写了个文件，可以单独运行；删除simple_wb_info.json相关内容。

2022.12.18
微博旧版切换按钮没了

2022.12.23
可以正常处理转发微博了
如果今天状态好就把评论数量限制写出来，在考虑要不要写成中间件

2022.12.26
新版微博请求正文/评论数据有个{ok:1}表示数据正常，之前是在spider里一个一个判断现在写成中间件了：MyCountDownloaderMiddleware
在meta里加{"my_count": 0}启动这个判断

暂时把获取评论关掉了。因为没写判断评论数量的代码，打开的话只能一直爬完全部

2023.02.20
收到报错：预写文件为空时重启动报错，我这边跑是可以处理空文件的，怪。把if提前了一点，空文件直接跳过。

2023.03.28
文件save_img_new，微相册链接存图片
文件to_vis_new  结果文件转换成可视化程序用的文件（可视化程序没公开）

2023.04.06
get_rcomm() 和 get_ccomm() 二合一 成 get_comm()
加了debug功能：页数限制

2023.04.07
没办法搞成用指令指定配置文件，指令对spider生效，但是setting和pipline没办法从指令读路径，这两又都需要用配置文件
写了run_backup，就是把一堆配置文件的设定依次爬一遍，配合写了批量改配置文件cookies的(感觉有些拉跨,但是能用)

2023.04.09
评论数量指定终于生出来了
获取评论本身还有bug（目前确定无法解决，见2023.04.10日志）

2023.04.10
有些评论点赞数无法获取不打算详细处理了，直接设成-1
部分子评论在pc端确定无法获取，详见结尾的问题记录
git弄不了空文件夹，给log文件夹里加了个文件

2023.4.11
部分根评论无法完全获取，详见结尾的问题记录
给requirements.txt里的两个指定了版本

2023.05.06
问题记录：评论限制失效(已修)

2023.06.17
修复bug：即使设为0也会获取一次子评论的bug
修复bug：评论数量限定重复计数

2023.06.24
问题记录： 判断长微博部分，要找一下key if text_len >= 240:


2024.03.10
添加配置项get_rwb_detail，设为0为不获取源微博详细数据，只获取转发页能获取到的，设为0则获取详细数据（发一次请求）
处理这种能看见转发但原博不可阅读的：https://weibo.com/6591638928/IpXyxmLuO

2024.03.17
增加配置项time_limit

2024.04.06
4月1号微博往headers和cookies里更新了XSRF-TOKEN所以我也得更新

2024.05.04
新增batch_backup.py

2025.02.14
把time_limit的判断修到了判断本页信息是否有效之后

2025.02.26
pipline生成结果文件一点优化
评论获取一点优化
增加批量运行小工具

2025.02.27
将指定config文件的变量合并到了setting.py，并且现在可以通过指令来指定config文件了
为实现用指令指定config，scrapy改为了2.11版本
修复爬不到child comm的bug

问题记录（微博的问题，不是我的）
部分微博根评论无法完全获取，根评论在获取到一定数量后会开始有一个很迷的逻辑，会返回有max_id但没有data的数据，要继续用新的max_id请求到第15次才会返回有内容的（太离谱了我感觉我以后自己看到都不信所以截了图在留档里），而且继续往后翻一些之后data会一直为空
部分微博（比如这个2803301701/Ir8yTbmQu）的子评论没办法完整获取，翻一些之后data会一直为空

